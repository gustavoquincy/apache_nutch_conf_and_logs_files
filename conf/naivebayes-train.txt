1	Developed by Andreas Keller et al. from Saarland Unversity, PLSDB is a resource containing more than 30,000 plasmid records retrieved from the NCBI nucleotide database. The web provides an interactive view of all obtained plasmids with their sequences and additional meta information such as plasmid length, isolation source, and host taxonomy.

1	ProteinGym is a large collection of Deep Mutational Scanning experiments that have been curated to evaluate how well computational methods can predict the functional impact of mutations on proteins. It allows testing how accurately different mutation effect prediction algorithms can forecast the fitness consequences of amino acid changes in proteins.

1	InterPro provides functional analysis of proteins by classifying them into families and predicting domains and important sites. To classify proteins in this way, InterPro uses predictive models, known as signatures, provided by several different databases (referred to as member databases) that make up the InterPro consortium. We combine protein signatures from these member databases into a single searchable resource, capitalising on their individual strengths to produce a powerful integrated database and diagnostic tool.

1	Mycobank is an online fungal taxonomic database that provides comprehensive information about fungal species, including their scientific names, classifications, synonyms, references as well as strain and culture information. It serves as a valuable resource for researchers, taxonomists, and enthusiasts in the field of mycology.

1	The UK Biobank is a significant biomedical database with comprehensive genetic and health data from 500,000 UK participants aged 40 to 69. It is accessible to approved researchers globally for studying common and life-threatening diseases. The database has contributed to medical progress and discoveries since 2006, collecting extensive biological, medical, and lifestyle data with participants' consent. This data helps understand disease experiences by connecting lifestyle information with health records.

1	This dataset provided the genome size data of prokaryotes (including bacteria and archaea), measured by pulse-field gel electrophoresis (PFGE).

1	This database provides the genome size data of over 6000 animal species. The genome size was measured as haploid DNA content (C-value) based on over 700 published resources.

1	This database provides the genome size data of over 12,000 plant species (including angiosperm, gymnosperm, pteridophyte, bryophyte, algae). The plant genome sizes were measured as C value, the DNA amount in the unreplicated gametic nuleus.

1	This database provides the genome size data of over 700 fungal species (including ascomycota, basidiomycota, chytridiomycota, glomeromycota, zygomycota). The genome sizes were measured as C values

1	The Microbiome Database (MDB) serves as a comprehensive repository of diverse microbial communities from various environments, offering a valuable resource for researchers and enthusiasts in the field of microbiology. MDB aggregates a wide range of data, including DNA and RNA sequences, metagenomic profiles, and associated metadata, providing a platform for the exploration and analysis of microbial diversity, interactions, and functions. This database plays a pivotal role in advancing our understanding of the intricate relationships between microorganisms and their ecosystems, fostering innovative research and contributing to breakthroughs in areas such as human health, ecology, and biotechnology. Whether investigating the human gut microbiome or studying microbial communities in natural environments, MDB offers an invaluable collection of data to unravel the mysteries of the microbial world.

1	The UCSC Genome Browser is an online and downloadable genome browser hosted by the University of California, Santa Cruz (UCSC). It is an interactive website offering access to genome sequence data from a variety of vertebrate and invertebrate species and major model organisms, integrated with a large collection of aligned annotations. Besides, The UCSC site hosts a set of genome analysis tools, including a FASTA format sequence alignment tool BLAT, a liftOver tool uses whole-genome alignments to allow conversion of sequences from one assembly to another or between species.

1	It is a database that aims to help understand the overarching functions and capabilities of biological systems like cells, organisms, and ecosystems using molecular-level data, particularly large datasets generated through genome sequencing and other high-throughput experimental techniques. The goal is to gain insights into the higher-level workings and behaviors of biological systems by analyzing the large amounts of molecular data now available.

1	This database provides the bacteria and Archaea  genome-based classification and identification,and you can used the  tools(eg.bioinformatics,Metagenomics analysis) analysis online.

1	Ensembl is a genome browser for vertebrate genomes that supports research in comparative genomics, evolution, sequence variation and transcriptional regulation. Ensembl annotate genes, computes multiple alignments, predicts regulatory function and collects disease data. Besides, The Ensembl site hosts a set of genome analysis tools, including BLAST, BLAT, BioMart and the Variant Effect Predictor (VEP) for all supported species

1	The Structural Classification of Proteins (SCOP) database categorizes proteins with known 3D structures from the Protein Data Bank. It organizes proteins into family groups, superfamily relationships, and fold categories based on structural and evolutionary connections. SCOP also includes Intrinsically Unstructured Protein Regions (IUPRs) and protein classes based on secondary structural content. Each classification node has a unique identifier, and the database is updated with new entries. Users can access SCOP through browsing or searching, and an API provides programmatic access. SCOP serves researchers, theoreticians, educators, and molecular biologists by offering insights into protein relationships and structures.

1	ResistanceMap is a global database about antibiotic use and resistance data , including human and animals, distributed in national or subnational level.

1	The Human Metabolome Database (HMDB) is a free online resource that provides comprehensive data on the small molecule metabolites present in the human body.

1	Addgene is a nonprofit organization that maintains a repository of plasmids for research purposes. Researchers can search and request plasmids from a wide range of sources. Addgene is also building a variety of educational resources, including protocols, blog posts, and eBooks. Plasmids 101 and CRISPR 101 blog series were designed to help scientists of all levels learn more about molecular biology, cloning, genome engineering, and more

1	Developed by Charles L. Nunn group from Duke UniversityThis database provides a compilation of parasites and pathogens from wild primate, carnivore and ungulate hosts across different continents and countries. The location, prevalence and transmission mode associated with each parasite and pathogen are also available from this database.

1	WormBase ParaSite is a specialized database focusing on the genomics and functional genomics of parasitic worms (helminths). It offers genome sequences, gene annotations, and comparative genomics tools for various parasitic species. Researchers use it to study gene functions, host-parasite interactions, and potential drug targets. The database aids in understanding parasite biology, evolution, and disease mechanisms, contributing to advancements in health and agriculture.

1	The Parasite Extinction Assessment and Red List (PEARL) is an initiative focused on evaluating the risk of extinction for various parasite species. Similar to the IUCN Red List, PEARL aims to highlight the importance of parasites in ecosystems and the potential consequences of their decline. By assessing factors like population size, distribution, and ecological impact, PEARL contributes to conservation strategies that consider the role of parasites in maintaining ecosystem balance and biodiversity. This project emphasizes the interconnectedness of all species and promotes a more comprehensive approach to conservation.

1	The CATH (Class, Architecture, Topology, Homology) database is a prominent resource in structural bioinformatics, offering a hierarchical classification system for protein structures. It arranges proteins into functional classes, further dividing them based on secondary structure arrangements, connections between these structures, and evolutionary relationships. This tiered approach aids in comprehending the intricate relationships between protein structures, their functions, and evolutionary origins. As a valuable tool, CATH assists researchers in tasks like structure prediction, functional annotation, and studying structural diversity across organisms, contributing significantly to our understanding of protein evolution and function.

1	The Host-Parasite Catalogue, devised by Dr. H.A. Baylis in 1922 and currently maintained by the Parasitic Worms Group, traces its origins to a meticulous record-keeping effort capturing host-parasite associations documented in scientific literature. Originally in manuscript form, this catalogue has evolved over time to become an invaluable resource for understanding the intricate relationships between hosts and parasitic worms. The meticulous cross-referencing of helminth parasites under host genera and the extensive bibliographic entries serve as a testament to the depth of information collected since its inception. This database, containing data extracted from over 70,000 references up until 1988, evolved further with the digital age. Between 1988 and 2003, a computerized version was curated, incorporating more than a quarter of a million host-parasite records from 28,000 references, complete with additional details about host species and localities. The online accessibility of this database offers researchers and enthusiasts the opportunity to explore a substantial portion of this comprehensive collection, shedding light on the fascinating world of host-parasite interactions, helminth diversity, and the evolutionary intricacies that bind them.

1	Strains in the CGSC collection include only non-pathogenic strains of Escherichia coli: predominantly K-12 derivatives, but a few B strains. The CGSC Database of Strains genetic information includes genotypes and reference information for the strains in the CGSC collection, the names, synonyms, properties, and map position for genes, gene product information, and information on specific mutations and references to primary literature. 

1	The Outfit-of-the-Day Fashion Dataset (OOTFD) stands as a valuable resource in the realm of fashion image analysis and classification. Comprising a diverse collection of images, OOTFD focuses on clothing items and their intricate combinations in different styles. This dataset serves as a foundation for training and evaluating deep learning models that can detect, classify, and recognize various clothing attributes within outfits. As fashion continues to merge with technology, OOTFD paves the way for advancements in clothing style recognition, outfit recommendation systems, and fashion AI, fostering innovation and accuracy in understanding and interpreting the ever-evolving world of attire.

1	This is an project of  NCBI  to identify antimicrobial resistance(AMR) genes .It provide not only  the AMR genes from the pathogens ,but also the genmoes with genotypes or phenotypes. Since the expansion of the database in 2021, AMR mutations, general stress response genes and virulence genes are also curated within NDARO for the clinically important pathogens

1	The AACR GENIE project is a large-scale international collaboration that aims to advance precision cancer medicine by linking extensive genomic data from cancer patients to clinical outcomes. GENIE will aggregate clinical-grade NGS data from thousands of patients across multiple institutions worldwide. By amassing this large dataset, GENIE will enable the discovery of new therapeutic targets, improve understanding of patient response to therapy, facilitate biomarker-driven clinical trials, and provide the statistical power needed to enhance clinical decision-making. Overall, the project fulfills an important unmet need in oncology by generating a prototype database of harmonized, real-world genomic and clinical data that can drive precision medicine forward.

1	The Bio-Med Big Data Center (Bio-Med BD Center) is a pioneering hub in China's biomedical research landscape. Our mission encompasses comprehensive data services, from management to mining, for researchers. We champion the development of big data infrastructure, set standards for integration and security, and align with national biomedical goals. By fostering interdisciplinary collaborations, we drive data-driven discoveries that reshape healthcare. Join us in unlocking the potential of big data for biomedical advancement.

1	DDBJ Center collects nucleotide sequence data as a member of INSDC(International Nucleotide Sequence Database Collaboration) and provides freely available nucleotide sequence data and supercomputer system, to support research activities in life science.

1	The SWISS-PROT database stands as a foundational resource in the realm of molecular biology and proteomics. Recognized for its accuracy and comprehensiveness, SWISS-PROT serves as a repository of protein sequence data that is meticulously annotated with crucial information about protein function, structure, classification, and evolutionary relationships. Researchers and scientists rely on this database to access detailed insights into individual proteins, ranging from their amino acid sequences to comprehensive annotations that elucidate their roles within biological processes. By offering a wealth of organized and curated data, SWISS-PROT not only supports protein sequence analysis but also contributes to broader scientific understanding, aiding in fields such as drug discovery, disease research, and comparative genomics. As a central component of the UniProt consortium, SWISS-PROT continues to facilitate breakthroughs in our understanding of proteins and their multifaceted roles in the intricate machinery of life.

1	The Arabidopsis Information Resource (TAIR) collects information and maintains a database of genetic and molecular biology data for Arabidopsis thaliana, a widely used model plant, including the complete genome sequence along with gene structure, gene product information, gene expression, DNA and seed stocks, genome maps, genetic and physical markers, publications, and information about the Arabidopsis research community. Besides, it also contains many analysis and visualization tools, including GO Term Enrichment, PhyloGenes, JBrowse, GBrowse, Synteny Viewer, SeqViewer, MapViewer, AraCyc Pathways, Integrated Genome Browser, BLAST, Pattern Matching, Motif Analysis, VxInsight®, Java TreeView, Bulk Data Retrieval, Chromosome Map Tool, Restriction Analysis, Gene Symbol Registry and Textpresso Full Text.

1	The Open Reaction Database(ORD) provides a structured data format for chemical reaction data, especially the high-throughput experimentation(HTE) data. As of mid 2023, the database has grown to more than 2M reactions, with the overarching goal to support machine learning and related efforts in reaction prediction, chemical synthesis planning, and experiment design.

1	The Cancer Genome Atlas (TCGA) Data is a groundbreaking resource that provides a comprehensive and detailed view of the genomic landscape of various cancer types. TCGA represents a collaborative effort to understand the genetic basis of cancer by collecting and analyzing genomic data from thousands of tumor samples. This dataset encompasses a wide range of molecular information, including DNA sequencing data to uncover somatic mutations, gene expression profiles to explore changes in gene activity, and copy number alterations that affect the number of copies of specific genes within cancer cells. TCGA data is further enriched with clinical information, allowing researchers to correlate genetic findings with patient outcomes. This multi-omics approach has revolutionized cancer research, leading to insights into the molecular drivers of cancer initiation, progression, and potential therapeutic targets.

1	CARD is an ontology-centric knowledgebase on the molecular determinants of antibiotic resistance. It can provide both reference set and software tools for guiding AMR research, particularly for ARG(Antibiotic Resistance Genes) annotation and discovery from genomic and metagenomic data. Additionally, CARD works towards harmonization with other AMR databases, specifically including those provided by the National Center for Biotechnology Information (NCBI), such as the Pathogen Detection Reference Gene Catalog

1	MGI is the international database resource for the laboratory mouse, providing integrated genetic, genomic, and biological data to facilitate the study of human health and disease. This resource also contains two tools, including Genome Analysis Tools and Prototype Analysis Tools.

1	The OpenFarm originated in 2013 in the FarmBot Whitepaper, the idea is to build a centralized, structured and open dataset that described how to grow plants based on specific environmental conditions and growing practices. The overarching aim is to break down borders through the open sharing of knowledge, increase participation in the food system, and help everyone become a better farmer or gardener. The source code is hosted on GitHub under the MIT license.

1	NextProt is a comprehensive protein knowledge platform that plays a pivotal role in advancing biomedical research and our understanding of the molecular mechanisms underlying various biological processes. This platform serves as a valuable resource for researchers, scientists, and clinicians by providing a wealth of information about proteins, their functions, interactions, and modifications. NextProt goes beyond mere sequence information, offering detailed functional annotations, curated data on genetic variants, post-translational modifications, and protein-protein interactions. By consolidating and curating data from various sources, NextProt facilitates the exploration of protein-related data in a unified and user-friendly manner, contributing to the elucidation of biological processes, the identification of potential therapeutic targets, and the advancement of personalized medicine.

1	PubMLST is a Public databases for molecular typing and microbial genome diversity. It have integrated population sequence data with provenance and phenotype information for over 130 different microbial species and genera.

1	FlyView is an image database dedicated to the developmental and genetic research of Drosophila, with a primary focus on gene expression patterns. The database compiles a vast collection of images from various time points and tissues during the developmental process of Drosophila, along with information related to specific gene expression. Researchers can utilize FlyView to browse, search, and compare these images, thus gaining a deeper understanding of the expression patterns of Drosophila genes across different developmental stages and tissues. This holds significant importance for the investigation of genetic regulation and developmental biology in Drosophila, as well as other relevant fields. Through FlyView, scientists can enhance their comprehension of the functionality and interrelationships of Drosophila genes, thereby contributing valuable information and resources to the advancement of life sciences.

1	Caco-2 permeability dataset by Wang et al. is a dataset used to measure the absorption of drugs through intestinal tissue by simulating it using a human colon epithelial cancer cell line (Caco-2). The dataset is divided into 8 tabs, SI1 lists data set drugs, their basic structural information, and experimental permeability values. Also, it includes the prediction permeability values of our four QSAR models. SI2 and SI3 list the training set and test set drugs and their descriptors after pruning, respectively. SI4 lists the structures of 12 outliers in the Caco-2 permeability data set for Boosting model. SI5 and SI6 list the basic structural information, experimental permeability values and the predicted values of the additional Caco-2 test set and MDCK test set, respectively. SI7 and SI8 list the structures of the outliers in external Caco-2 and MDCK permeability data sets, respectively

1	Nucleotide Sequence Databases serve as critical repositories for genetic information in the form of DNA and RNA sequences. These databases house an extensive collection of sequences obtained from various organisms, ranging from microbes to plants and animals. The sequences are typically annotated with information about genes, coding regions, non-coding regions, regulatory elements, and more. Researchers can access these databases to search for specific sequences, compare sequences using tools like BLAST for similarity analysis, and explore genetic variations within and between species. Nucleotide Sequence Databases play a pivotal role in advancing molecular biology research, enabling scientists to uncover insights into evolutionary relationships, gene functions, and the genetic basis of various traits and diseases. These databases facilitate a deeper understanding of the fundamental molecular components that underlie life on Earth and have contributed to numerous discoveries across biological disciplines.

1	A database of conserved protein families and domains. Pfam is a member database of InterPro (www.ebi.ac.uk/interpro). Pfam data is now accessible via the InterPro website.

1	Microarray data and gene expression databases are essential tools for studying gene activity in various contexts. Microarrays allow simultaneous measurement of gene expression levels, aiding in identifying genes associated with specific conditions. Gene expression databases like GEO and ArrayExpress store vast transcriptomic data, enabling researchers to analyze gene expression patterns across diverse samples. These resources facilitate the discovery of regulatory insights, biomarkers, and molecular mechanisms underlying biological processes and diseases, fostering collaboration and advancing functional genomics research.

1	The Fungal Genetics Stock Center (FGSC) is an organization located in Kansas City, Kansas, United States, dedicated to collecting, preserving, and distributing fungal genetic materials to support fungal genetics and molecular biology research. Established in 1960, FGSC is a non-profit organization that aims to facilitate research and advancement in the field of fungal genetics.The primary objectives of FGSC include:Collection and Preservation of Fungal Genetic MaterialsDistribution of Genetic MaterialsInformation Sharing and TrainingTechnical Support and Consultation

1	A design repository for sharing gene circuit design in Synthetic Biology Open Language(SBOL). The dataset is led by the efforts of University of Utah and Newcastle University. It's inclusive in terms of the availability of preexisting designs, e.g. SEVA-DB and SEVA format. Check it out if you are a synbio experimentalist!

1	Ensembl has produced high-quality genomic resources for vertebrates and model organisms for more than twenty years. Of course, other organisms such as bacteria, virus, protists, fungi and other eukaryotic genes or genomes are also collecting into the database. All Ensembl data, software and tools are freely available for download and are accessible programmatically.

1	RiboD is a database dedicated to cataloging and providing information about prokaryotic riboswitches. Riboswitches are RNA-based regulatory elements found in the untranslated regions of certain genes in bacteria and other prokaryotic organisms. They are capable of binding to specific small molecules, often metabolites or coenzymes, and altering the gene's expression based on the presence or absence of these molecules.The RiboD database focuses on collecting data related to prokaryotic riboswitches, including their sequences, secondary structures, ligand-binding capabilities, and associated genes. This database serves as a valuable resource for researchers and scientists interested in exploring the regulatory roles of riboswitches and their implications for gene expression and cellular processes.

1	BioCyc is a large collection of over 20,000 Pathway/Genome Databases for both model organisms like yeast as well as thousands of microbes. It also includes software tools to analyze the data. BioCyc contains a vast amount of curated data gathered from over 130,000 scientific publications, making it an extensive encyclopedic reference on pathways and genomes.

1	The Bacterial Diversity Metadatabase BacDive is the worldwide largest database for standardized bacterial phenotypic information.BacDive offers data on  93,254 bacterial and archaeal strains, including 19,313 type strains and thereby covers approx. 90% of the validly described species. The majority of the BacDive data is manually annotated and curated.

1	The SILVA database primarily contains 16S, 18S, and 23S rRNA gene sequences from various domains of life, including bacteria, archaea, and eukaryotes. These sequences are used to study microbial diversity, classification, and evolutionary relationships. The sequences in the database are curated, corrected, and classified, ensuring high quality and reliability.The applications of the SILVA database span various fields, including:1) Microbial Diversity Research;2) Taxonomy Studies3) Evolutionary Research4) Functional Prediction5) Ecological Studies

1	MetRxn is a knowledgebase that standardizes information on metabolites and biochemical reactions by integrating data from various sources like BRENDA, KEGG, MetaCyc, Reactome, and metabolic models. It unifies this data into a single consistent dataset. Metabolite entries contain matched synonyms, determined protonation states, and links to unique chemical structures. Reaction entries are elementally and charge balanced through the use of algorithms that compare names, formulas, and structures. A key utility of MetRxn is enabling the download of standardized genome-scale metabolic models for many organisms. It also facilitates rapid reconstruction of new models by providing standardized metabolic data. Overall, MetRxn integrates disparate sources into a unified knowledgebase of metabolites and reactions with standardized descriptions to enhance the accuracy and utility of metabolic models.

1	The Comparative RNA Web (CRW)  is a databases for comparing RNA sequence and structure  from different RNA families. The primary focus of the CRW is secondary structures for the rRNAs and the group I and II introns.

1	The UNITE community is a collaborative network of scientists, researchers, and individuals who are involved in the field of mycology and molecular biology. The primary focus of the UNITE community is the study and research related to the nuclear ribosomal Internal Transcribed Spacer (ITS) region, a region of DNA commonly used for species identification and classification, particularly in fungi. Researchers and individuals within the UNITE community can interact with the species hypotheses, contribute annotations to sequences, and utilize various search and query tools provided by the UNITE database.

1	AlgaeBase is a global algal database of taxonomic, nomenclatural and distributional information.Recently, there is 172,305 species and infraspecific names, 23,355 images, 67,939 bibliographic items and 541,432 distributional records in data.

1	CeCaFDB is an open-access, curated database for fluxomics data from studies on central carbon metabolism across different organisms. It contains quantitative flux results obtained using 13C metabolic flux analysis on 36 organisms, comprising 581 cases in total. The database covers literature-derived fluxomics data and allows text search across the compiled data. It also enables interactive visualization of flux distributions along with compartment information, powered by Cytoscape Web API, to help interpret the data. CeCaFDB provides four modules to calculate similarity scores or align flux distributions. Using these modules, users can query the database to find similar flux maps based on similarity comparisons. Overall, CeCaFDB serves as a specialized platform to store, search, analyze, visualize and compare fluxomics data on central carbon metabolism from various biological studies.

1	Greengenes was a widely used resource and database in the field of microbiology, specifically focused on the study of microbial communities and diversity, particularly in the context of the 16S ribosomal RNA (rRNA) gene. The 16S rRNA gene is a segment of the bacterial and archaeal genomes that encodes a component of the ribosome, a cellular structure essential for protein synthesis.The Greengenes database was developed to aid researchers in the identification and classification of microorganisms based on their 16S rRNA gene sequences. It provided a curated collection of these sequences, along with tools and resources for taxonomic and phylogenetic analysis of microbial communities. This was particularly important for studying complex environments such as soil, water, and the human microbiome.

1	BioModels is a repository maintained by EMBL-EBI to foster biological and medical mathematical model exchange where you can browse and inspect models of different format, e.g. MATLAB, SMBL etc. You can also search models based on GO, diseases, organisms, modeling approaches, e.g. ODE, PDE, MC, constraint-based etc. You can search models in different journals, e.g. PLOS One etc. There are even more specifiers to be explored. Check it out!

1	The RNAcentral is an  database about non-coding RNA(ncRNA) sequence witch collecting  all ncRNA types from a broad range of organisms.You can identifies genomic locations for ncRNA sequences in 296 species, and aslo functional annotation of genomes, such as tRNA secondary structures, Gene Ontology annotations, and miRNA-target interactions.

1	"Tabula Muris, which translates to ""Mouse Cell Atlas"" in Latin, is a biological research initiative aimed at gaining a deeper understanding of the single-cell transcriptomes of the mouse species Mus musculus. The project's objective is to comprehensively analyze the gene expression of individual cells across various tissues and organs of the mouse, leading to a more comprehensive insight into cell types, functions, and their interrelationships.The Tabula Muris project primarily employs single-cell RNA sequencing, a technique that allows researchers to detect and quantify gene expression at the single-cell level. By analyzing the sequencing data from a large number of cells, researchers can identify different cell types, subtypes, and states. Additionally, this approach reveals cell-to-cell interactions and their spatial distribution within the organism."

1	BiGG Models is a database of over 75 highly curated, genome-scale metabolic models. The website allows users to browse, search and visualize the metabolic models interactively. The models are integrated with genome annotations and external databases. Reaction and metabolite identifiers are standardized across all models per community conventions, enabling easy comparison. BiGG Models also provides a comprehensive API for accessing the models programmatically and integrating them with modeling and analysis software tools. Overall, BiGG Models compiles high-quality metabolic reconstructions in a unified platform with interfaces and standardization to facilitate analysis and tool integration.

1	"""IMSR"" likely refers to the ""International Mouse Strain Resource,"" which is a database and platform that provides information and data about mouse strains. The IMSR aims to offer accurate and comprehensive information about mouse strains to researchers and laboratories, assisting them in genetic research, disease model development, and other biomedical studies. This resource gathers information about mouse strains from different laboratories around the world, including their genetic backgrounds, phenotypic characteristics, genotype data, and more.Researchers can use IMSR to search for specific mouse strains, learn about their traits, genetic information, and availability. This helps them select suitable mouse models for their research purposes."

1	The Therapeutics Data Commons (TDC) is an open science project started at Harvard that provides AI/machine learning ready datasets and tasks focused on therapeutics research. It offers an ecosystem of tools, leaderboards, and community resources to support work in this area. Key elements include data functions, model benchmarking strategies, validated data splits, data processors, public leaderboards, and molecule generation tools. All of these resources are integrated and can be accessed through an open Python library. The goal of TDC is to advance therapeutics research through open data sharing, benchmarking, and community engagement.

1	The Bacterial and Viral Bioinformatics Resource Center (BV-BRC) is an information system about bacterial and viral infectious diseases.Unified data model, enhanced web-based visualization and analysis tools, bioinformatics services, and a powerful suite of command line tools was provided for helping biomedical researchers to analyse the growing body of genome sequence and other omics-related data.

1	The European Arabidopsis Stock Centre (NASC) is a renowned research resource and repository dedicated to the plant model organism Arabidopsis thaliana. NASC serves as a centralized hub for storing and distributing a wide variety of Arabidopsis genetic resources, including mutant lines, natural accessions, and genetic markers. Researchers from around the world can access these resources to study various aspects of plant biology, such as genetics, development, physiology, and responses to environmental stimuli.

1	scRNASeqDB is developed and curated by UT Health to facilitate the understanding of transcriptome in a single cell. It contains 36 single cell gene expression datasets from GEO involving 8910 cells from 174 cell groups. It features heatmap, boxplot of gene expression, gene correlation matrix, GO and pathway annotation. 

1	CDC(centers for disease control and prevention) is the nation’s leading science-based, data-driven, service organization that protects the public’s health.You can find the  all kinds of imformation and news about public's health in CDC, such as outbreaks, environmental health,violence and safety, prevention of common diseases and so on.

1	The Ring-Hydroxylating Oxygenase (RHO) database is a resource that collects and compiles information about a specific group of enzymes known as ring-hydroxylating oxygenases. These enzymes play a crucial role in the degradation of aromatic compounds, which are organic molecules containing one or more rings of carbon atoms. Besides, the RHO database contains information about the genetic sequences, structural features, biochemical properties, and other relevant data related to different types of ring-hydroxylating oxygenases

1	ClinicalTrials.gov curated privately and publicly funded clinical studies, the service is provided by US National Library of Medicine. For a specific clinical trial, you can access study description, study design, arms and interventions, outcome measures, eligibility criteria, contacts and locations in this database.

1	This library is a public and easily accessible resource database of images, videos, and animations of cells, capturing a wide diversity of organisms, cell types, and cellular processes.It can help resercher and clinicians fully appreciate the structure and dynamic behavior of cells which will helpfully to their reserch , diagnosis or treatment.

1	OxDBase, a repository of biodegradative oxygenases, provides an extensive compilation of information covering over 240 oxygenases. This diverse group includes both dioxygenases and monooxygenases, pivotal in orchestrating the biodegradation of xenobiotic compounds. Delving into the enzyme entries reveals a wealth of intricate details, encompassing their EC numbers, synonyms, linked reactions, familial and subfamilial categorizations, structural revelations, gene connections, and references to pertinent literature. These entries seamlessly interface with a multitude of external databases, including BRENDA, LIGAND, ENZYME, and UM-BBD, culminating in an expansive tapestry of contextual insights.

1	A molecular recognition database, contains 2.8M data for 1.2M Compounds and 9.2K Targets. Of those, 1,279K data for 585K Compounds and 4.5K Targets were curated by BindingDB curators.The Binding Database is based at the Skaggs School of Pharmacy and Pharmaceutical Sciences at the University of California, San Diego, La Jolla, CA.

1	"""Senescence.info"" is an educational and information resource on the science of aging. You can get the aging, or senescence infotmation through biology of aging, genmoic, and global perspective form different kind of animal and human. "

1	AthaMap offers a comprehensive genome-wide cartography of potential binding sites for transcription factors and small RNAs (TFBS) within Arabidopsis thaliana. The foundation of AthaMap's data lies in established transcription factor (TF) binding specificities, which are available in the form of alignment matrices or experimentally determined individual binding sites. The methodology encompasses both matrix-based and pattern-based screenings, leading to the detection of latent transcription factor binding sites across the Arabidopsis thaliana genome (specifically based on TAIR release 8).The compendium of 211 transcription factors encompassed within AthaMap, along with corresponding references and outcomes of screenings, is presented on the Documentation page. Through the employment of the Search function, users can retrieve the sequence linked to a particular genomic position or gene. This sequence is then displayed within a dedicated window, highlighting conceivable transcription factor binding sites.

1	The full text of bioRxiv articles can be accessed in bulk for text and data mining purposes through a dedicated Amazon S3 resource. The processed PDF and XML files from bioRxiv are uploaded monthly to this S3 bucket, typically finishing in the first few days of each new month. To access the files, you need an AWS account. The bioRxiv S3 bucket is located in the US East (Northern Virginia) region and can be accessed at the URL s3://biorxiv-src-monthly.

1	"OriTDB is a database of bacterial mobile genetic elements, such as integrative and conjugative elements and plasmids. Especially, it provide ""oriTfinder"", a web-based tool for the identification of origin of transfers in DNA sequences of bacterial mobile genetic elements. In addition, the server also detects the other transfer-related modules, including the potential relaxase gene, T4CP gene and the type IV secretion system gene cluster, and the putative genes coding for virulence factors and acquired antibiotic resistance determinants."

1	TargetScan is a widely recognized and influential bioinformatics tool and database used in the field of molecular biology and genomics. It is primarily employed for predicting microRNA (miRNA) target sites within the 3' untranslated region (UTR) of messenger RNA (mRNA) molecules. TargetScan helps researchers identify potential regulatory interactions between miRNAs and their target genes, shedding light on post-transcriptional gene regulation mechanisms. Here are some key features and aspects of TargetScan: MiRNA Target Prediction Conservation Analysis Gene Annotation and so on. Overall, TargetScan is an essential resource for researchers studying gene regulation, miRNA biology, and the intricate mechanisms that govern gene expression.

1	PubMedQA is a new biomedical question answering dataset collected from abstracts on PubMed. The task in PubMedQA is to answer research questions with yes, no, or maybe (e.g. Do statins given before surgery reduce atrial fibrillation after coronary bypass?). The dataset contains 1,000 expert-annotated, 61,200 unlabeled, and 211,300 artificially generated question-answer pairs. Each PubMedQA example has (1) a question derived from a research paper title, (2) a context which is the abstract without the conclusion, (3) a long answer which is the conclusion and presumable answers the research question, and (4) a yes/no/maybe answer summarizing the conclusion. PubMedQA is the first QA dataset requiring reasoning over biomedical research texts and their quantitative contents to answer the questions. Our top performing model, BioBERT fine-tuned on the long answers' bag-of-words statistics, achieves 68.1% accuracy, compared to single human performance of 78.0% and a majority baseline of 55.2%, leaving ample room for improvement.

1	ICEberg 2.0 is an updated database that provides comprehensive information about bacterial integrative and conjugative elements (ICEs) or integrative and mobilizable elements (IMEs). ICEberg 2.0 provides an online tool ICEfinder to predict ICEs or IMEs in bacterial genome sequences. It combines a similarity search for the integrase, relaxase and/or type IV secretion system and the co-localization of these corresponding homologous genes. 

1	The Long Non-Coding RNA and Disease Database, often abbreviated as LncRNA and Disease Database or LncRNADisease, is a comprehensive and specialized resource that serves as a repository of information related to long non-coding RNAs (lncRNAs) and their associations with various diseases. The LncRNA and Disease Database provides researchers, scientists, and clinicians with a valuable platform for exploring the following aspects: 1) LncRNA-Disease Associations; 2) Functional Annotations; 3) Experimental Evidence; 4) Data Integration; 5) Search and Query 6) Visualization Tools; 7) Potential Therapeutic Targets.

1	ZINC20 library is prepared for Deep Docking-accelerated virtual screening. As a fully enumerated database, ZINC can be searched precisely using explicit atomic-level graph-based methods, such as SmallWorld for similarity and Arthor for pattern and substructure search, as well as 3D methods such as docking.

1	BorreliaBase is a phylogeny-centered browser that focuses on providing comparative information among sequenced  Borrelia genomes, though stain, gene family, replicions, core genome, plasmid, blast and transcripome 7 modules.

1	COCONUT Online is an open access platform for storing, searching, and analyzing natural products. It aggregates data from over 50 public natural product databases and is free to use without restrictions. Each entry represents a natural product structure and includes associated information like stereochemistry, literature sources, producing organisms, geographical sources, and precomputed molecular properties, when available. COCONUT Online utilizes over 50 open natural product databases. One advanced search option allows specifying which databases to search. It is developed by the Cheminformatics and Computational Metabolomics research group at Friedrich-Schiller-University in Jena, Germany.

1	"The ""lncRNASNP2"" database is a resource for the study of long non-coding RNAs (lncRNAs) and their interactions with single nucleotide polymorphisms (SNPs). lncRNAs are a class of RNA molecules that do not code for proteins but play important roles in gene regulation and various cellular processes. SNPs are variations in a single nucleotide (DNA building block) that can be associated with various traits, diseases, or phenotypic differences in individuals. Features and information provided by the lncRNASNP2 database may include: 1) SNP-lncRNA interactions; 2) Disease associations; 3) Functional annotations; 4) Search and query tools."

1	Plasmid ATLAS (pATLAS) is a web-based tool enabling searching for a specific plasmid (or plasmids) of interest, visualize the available plasmid database and to identify plasmids contained in High Throughput Sequencing data. It allows searching by plasmid name, bacterial host taxa, antibiotic resistance and virulence genes, plasmid families, and by sequence length and similarity.

1	RNALocate is a bioinformatics tool and database designed to predict and annotate the subcellular localization of RNA molecules in various organisms. It is particularly focused on providing insights into the intracellular distribution of non-coding RNAs (ncRNAs) and messenger RNAs (mRNAs). Understanding the subcellular localization of RNA is crucial for unraveling their functional roles within cells and organisms.

1	LOTUS curated 750,000+ referenced strcuture-organism pairs to facilitate natural products research. It's hosted in several sites, and the Wikidata version allows community to curate and add novel data. It's similar to COCONUT in a sense that the user interface enables to browse compounds, perform advanced search specifying molecular formula, molecular weight, number of carbons, number of nitrogens, number of heavy atoms, and several molecular descriptors such as NP-likeness score, Apol, AlpgP, fractional FSP3, number of Spiro atoms, etc. You can also use InChl or SMILES to hand draw the chemical structure and the database would find the corresponding natural products. Now LOTUS supports data download with SDF format and in a MongoDB dump. It is developed by the Cheminformatics and Computational Metabolomics research group at Friedrich-Schiller-University in Jena, Germany.

1	Web-assisted symbolic plasmid synteny (WASPS:) is a web service granting protein and DNA sequence similarity searches against a database comprising all completely sequenced natural plasmids from bacterial, archaeal and eukaryal origin. This database pre-calculates orthologous protein clustering and enables WASPS to generate fully resolved plasmid synteny maps in real time using internal and user-provided DNA sequences.

1	LNCipedia stands as an invaluable and all-encompassing resource within the realm of molecular biology and genomics. It stands apart as a specialized database meticulously curated for long non-coding RNAs (lncRNAs), a unique class of RNA molecules devoid of protein-coding potential. Instead, lncRNAs wield formidable influence in orchestrating gene expression and orchestrating a plethora of intricate cellular processes. LNCipedia serves as the epicenter, a repository teeming with knowledge concerning these enigmatic non-coding RNAs, thereby endowing researchers and scientists with a treasure trove of data to delve into and unravel the profound roles lncRNAs play in both health and disease. The LNCipedia also provided 1) LncRNA annotations; 2) Expression profiles; 3) Functional insights; 4) Sequence data; 5) Links to research literature; 6) Cross-references.

1	The Protein Data Bank (PDB) was created at Brookhaven National Laboratories in 1971 to serve as a repository for biological macromolecular crystal structures. The PDB contains primary data submitted by depositors, including coordinates as well as general information required for all deposited structures and details specific to the structure determination method. The PDB provides open access to around 200,000 rigorously validated and expertly curated 3D structures of biological macromolecules like proteins, nucleic acids, carbohydrates, and their complexes with other molecules. Because of the ‘function follows form’ axiom in biology, 3D biostructures archived in the PDB have enabled myriad important scientific breakthroughs by basic and applied researchers.

1	ENCORI (The Encyclopedia of RNA Interactomes) and starBase are valuable resources in the field of RNA biology and cancer research. They provide researchers with comprehensive information and tools to study non-coding RNAs and RNA-protein interactions.ENCORI is a web-based platform and resource that focuses on RNA-related research, especially non-coding RNAs (ncRNAs) like microRNAs (miRNAs) and long non-coding RNAs (lncRNAs).It offers a wide range of functionalities, including data mining, analysis, and visualization tools, making it a valuable resource for researchers investigating RNA biology. Researchers can use ENCORI to explore miRNA and lncRNA expression profiles across various tissues, diseases, and conditions. ENCORI also provides information on RNA-protein interactions, allowing users to investigate the binding partners of specific RNAs and the functional implications of these interactions.It supports the analysis of RNA-seq data, CLIP-seq data, and other high-throughput sequencing data to gain insights into RNA biology.

1	"The database of useful biological numbers. BioNumbers is designed to be highly searchable and queries can be performed by keywords or browsed by menus. BioNumbers is coordinated and developed at the Milo lab in the Weizmann Institute of Science in Israel. BioNumbers currently attracts >3000 visitors a month from over 50 countries. Some popular Bionumbers include ""Number of hairs on human head"", ""Average duration of a single eye blink"", ""One unit of OD600 corresponds to a cell wet weight and a cell dry weight of"", ""Length of neuron from base of spine to big toe-longest cell in human body"", ""Size of glucose molecule (open chain form)"", ""Density and mass of each organ/tissue"", ""Genomic DNA amount in diploid cell"", ""Identification of total proteins in A. baumannii DU202 cultured in LB medium supplemented with imipenem"", ""Percent of protein in body that is collagen"", ""Number of blood and immune cells distributed throughout the human body"", ""Reaction times to sound, light and touch"", ""Ratio of cell dry weight (g/L)/OD600"", ""Cell concentration for culture with OD600 of 1"", ""Human body mean volume"", ""Number of cells in colony"", ""Empirical elemental formula for biomass"", ""Cell concentration for culture with OD600 of 0.1"", ""Diameter of HEK-293 cell"", ""Doubling time of ""normal"" laboratory haploid strain"", ""Diameter of neutrophil"". "

1	The Database for Annotation, Visualization and Integrated Discovery (DAVID) provides a comprehensive set of functional annotation tools for investigators to understand the biological meaning behind large lists of genes. 

1	miRWalk is a comprehensive and widely used database that is dedicated to the exploration and analysis of microRNA (miRNA) interactions with target genes. MicroRNAs are small, non-coding RNA molecules that play a crucial role in regulating gene expression by binding to the 3' untranslated region (UTR) of target messenger RNA (mRNA) molecules, thereby either inhibiting their translation or promoting their degradation. Understanding these miRNA-target interactions is essential for unraveling the complex mechanisms of gene regulation in various biological processes, including development, disease, and cellular homeostasis.

1	AlphaFold is an AI system developed by DeepMind that predicts a protein's 3D structure from its amino acid sequence. Partnered with EMBL-EBI, it makes the predictions freely available to the scientific communities. The latest database release contains over 200 million entries, providing a comprehensive coverage of UniProt. Currently there are many variants of the original AlphaFold database, such as the classifications of proteins based on whether it's knotted or not, which can be explored here: https://github.com/agemagician/ProtTrans .

1	STRING is a database of known and predicted protein-protein interactions, both physical interactions as well as functional associations for any sequenced genome of interest.You can search protein by names,  family names, sequences, pathway and so on.

1	RegulonDB is the primary database on transcriptional regulation in Escherichia coli K-12 containing knowledge manually collected from original scientific publications, complemented with high throughput datasets and comprehensive computational predictions. It's estimated to cover 20% of the major actors of transcriptional regulation, i.e. promoters, binding sites, transcriptional factors, transcriptional units, operons and regulons.

1	DIANA Tools refers to a specific set of bioinformatics software tools and resources developed by the DIANA (DNA Intelligent Analysis) Lab for the analysis and study of microRNAs (miRNAs) and their functions. miRNAs are short RNA molecules that play a critical role in the regulation of gene expression and are involved in various biological processes, including development, cell differentiation, and disease. DIANA Tools miRNA provides a range of computational and analytical tools tailored for miRNA research and analysis. Some of the key features and functionalities of DIANA Tools miRNA include:1) miRNA Prediction; 2) Target Prediction; 3) Functional Enrichment Analysis; 4) Expression Analysis; 5) Interaction Networks; 6) miRNA Disease Associations; 7) Integration with Other Data Sources; 8) Visualization.

1	The Pf-Phospho is a database  for prediction of phosphosites by training Random Forest classifiers using a large data set of 12 096 phosphosites of Plasmodium falciparum and Plasmodium bergei. Based on the availability, the phosphosites data has been mined from published literature studies of the mass-spectrometry based phosphosite identification experiments covering different life stages of the parasite.

1	Reactome curated human biological processes, and distinguished from KEGG and MetaCyc with a focus on solely Homo sapiens. It systematically links human proteins to their functions and thus provides a guidebook on somatic tumorigenesis. Reactome version 78 has entries for 10726 of the 20442 predicted human protein-coding genes, involved in 13890 reactions annotated from 34025 literature sources. These reactions are grouped into 2546 pathways, e.g. IL-15 signaling, phosphatidylinositol phosphate metabolism and receptor-mediated mitophagy, collected under 28 superpathways, e.g. immune system, metabolism and autophagy. 

1	SomamiR is a comprehensive database dedicated to cataloging cancer-related somatic mutations occurring within microRNAs (miRNA) and their associated target sites. These mutations have the potential to disrupt the intricate interactions between miRNAs and competing endogenous RNAs (ceRNA), which encompass various RNA types such as mRNAs, circular RNAs (circRNA), and long noncoding RNAs (lncRNA). SomamiR is designed to serve as an invaluable resource for researchers by offering an integrated platform for the systematic analysis of these somatic mutations and their functional implications. The SomamiR database is user-friendly and can be explored through several intuitive methods: 1) Somatic mutations in miRNA sequences; 2) Somatic mutations in experimentally identified miRNA target sites; 2) Somatic mutations in predicted miRNA target sites; 3) Biological pathways impacted by somatic mutations in miRNA target sites; 4) Genes associated with cancer risk that contain miRNA related somatic mutations.

1	AnimalTFDB is a comprehensive database including classification and annotation of genome-wide transcription factors (TFs) and transcription cofactors in 183 animal genomes. It provied annotation in multiple aspects, including gene expression, basic gene information, paralog and ortholog information, transcription factor binding sites, pathway, phenotype, gene ontology, post-translational modification and mutation information.

1	miRNEST is a comprehensive repository encompassing microRNA data from animals, plants, and viruses. This database offers a rich array of features, including:a) Curated microRNAs sourced from our high-throughput predictions, complemented by data from external databases.b) Predicted targets for plant candidates along with experimental support for these target interactions.c) Integration of data from 15 external databases, encompassing a wide range of information such as sequences, polymorphisms, expression patterns, and promoter regions.d) mirtrons, miRNA gene structures, degradome data and more.

1	The PANTHER(Protein Analysis THrough Evolutionary Relationships) database is a publicly available resource that provides information about protein evolution and function. It represents protein families as phylogenetic trees to show how related proteins have evolved over time. PANTHER also includes curated models that predict protein function based on how functions are conserved or have diverged among evolutionarily related proteins. The data and tools in PANTHER can be used for various research applications in protein science, including searching, browsing, downloading, and analyzing the data.

1	MarineTraffic is a widely used online platform and mobile application that provides realtime information about the movements of ships and vessels around the world. It offers a variety of services and features related to maritime tracking, including:1. Vessel Tracking: MarineTraffic allows users to track the positions and movements of ships, boats, and other maritime vessels in real-time on an interactive map. This information is useful for shipowners, maritime professionals, and enthusiasts.2. Port Information: The platform provides detailed information about ports and harbors worldwide, including data on port facilities, port traffic, and weather conditions in those areas.3. Voyage Data: Users can access historical voyage data for specific vessels, including information on their past routes, speed, and arrival/departure times at various ports.4. Notifications: MarineTraffic offers customizable notifications that can alert users when a specific vessel arrives at or departs from a particular port or area of interest.5. Weather Information: Users can access weather data, including wind speed and direction, wave height, and atmospheric conditions, to help plan and monitor maritime activities.6. AIS (Automatic Identification System): MarineTraffic relies on AIS technology, which is mandatory for most commercial vessels, to gather real-time data. AIS transponders on vessels broadcast information such as their position, speed, and course, which is picked up by land-based AIS receiving stations and satellites.7. Mobile App: MarineTraffic offers a mobile app for both Android and iOS devices, allowing users to access its features on the go.

1	"Welcome to the RasMol and OpenRasMol web site. This site was established in mid-September 2000 to provide a home for developers of Open Source versions of RasMol. In May 2002, it also became a home page for users of RasMol. RasMol is an important scientific tool for visualisation of molecules created by Roger Sayle in 1992. RasMol is used by hundreds of thousands of users world-wide to view macromolecules and to prepare publication-quality images. Science is best served when the tools we use are fully understood by those who wield those tools and by those who make used of results obtained with those tools. When a scientific tool exists as software, access to source code is an important element in achieving full understanding of that tool. As our field evolves and new versions of software are required, access to source allows us to adapt our tools quickly and effectively.There has always been free access to the source of the main line of RasMol development. With the creation of the RasMol 2.7 series of releases starting in 1999, RasMol formally became an open source program. There is some confusion about the meaning of the phrase ""open source"". In the early days of software development, most scientific software source code was freely and openly shared with a minimum of formalities. These days, it appears that carefully drawn legal documents are necessary to protect free access to the source code of scientific software. We are all deeply indebted to Richard Stallman for showing us how a creative combination of copyrights and seemingly restrictive licenses could give us truly unfettered freedom to use programs, to read their source code and to develop new versions. The GNU project, and the Linux project have shown that an open source approach works. Until the RasMol 2.7.3 release, we had not used the GNU General Public License (the ""GPL"") for OpenRasMol in the past, but the OpenRasMol conditions for use have correctly been called ""GPL-like"" and starting with RasMol 2.7.3, RasMol may now be distributed under the GPL. In view of the increasing used of GPL'd packages to support new features in RasMol, it is best to use the GPL for all versions from RasMol 2.7.3 onwards. This is certainly the case for binary releases from RasMol 2.7.5 onwards.You can find a complete explanation of the OpenRasMol conditions for relases prior to the 2.7.3 release (RASLIC) in the page on Copying and Distribution. If you are a user of OpenRasMol programs, you will find that the copyrights and notices ask little more of you than that you avoid mistakes by others by keeping the notices with copies, display scientific integrity by citing your sources properly and treating this like other shared scientific developments by not inferring a warranty. If you are a software developer and wish to incorporate what you find here into new code, or to pick up bits and pieces and used them in another context, the situation becomes more complex. Read the copyrights and notices carefully. You will find that they are ""infectious"". Whatever you make from our Open Source code must itself be offered as Open Source code. In addition, in order to allow users to understand what has changed and to ensure orderly development you have to describe your changes.IMPORTANT NOTE:Future releases of RasMol will continue to offer the GPL and RASLIC as alternative licenses for the source code, but, in order to conform to the license conditions of various libraries to which executables may be linked, starting with RasMol 2.7.5 release, the GPL is the only valid license to use the binary distributions.There is a lot still to be done before this site is fully functional. Many links and features need to be added. With your help, with your comments, suggestions and corrections, and with contributions of new Open Source RasMol code and documentation, hopefully this site will evolve into an increasingly useful tool for the community."

1	ModelArchive is the archive for structural models which are not based on experimental data and complements the PDB archive for experimental structures and PDB-Dev for integrative structures. ModelArchive is being developed following a community recommendation during a workshop on applications of protein models in biomedical research.Any type of macromolecular structure which would otherwise be suitable for the PDB but whose coordinates are not based on experimental data can be deposited in ModelArchive. This includes single chains or complexes consisting of proteins, RNA, DNA, or carbohydrates including small molecules bound to them. The modelling methods can be pure in silico predictions as found in de novo models or based on experimental structures such as homology models or modified structures including docked ligands, modelled variants, post-translational modifications (e.g. glycosylated structures), etc.The main purpose of a deposited model is to supplement a manuscript for which the model was generated and to make the model accessible for the interested reader. The secondary purpose is to make all deposited models findable, accessible, interoperable and reusable (FAIR) for interested researchers. As a result, ModelArchive provides a unique stable accession code (DOI) for each deposited model, which can be directly referenced in the corresponding manuscripts. Besides the actual model coordinates, archiving of models should include sufficient details about the purpose of the modelling, the source of sequences for the macromolecules, the modelling steps performed, and estimates of model quality to assess the applicability of the model for specific applications.

1	Protocols.io is a cookbook aimed to bring structure to the academic research, to mitigate the gradual loss of knowledge around protocol optimization by sharing methods on protocols.io in your company or lab, you make sure that knowledge stays with the team, even if the scientist leaves. It also helps to keep the protocols up-to-date and make sure everyone is using the most recent version. It serves as an alternative Google Scholar for experimental protocols.

1	Lexicomp is a subscription-based pharmacological database app that encompasses everything you might need to know about medications. The app requires you to have a subscription service to be able to access the 20 pharmacological databases it has. There are three subscription plans, and each offers a different number of databases you can access. Having access to all databases will give the healthcare professional all—if not more—the information on a medication.

1	Marine microplastics are tiny plastic particles that have a size range from a few micrometers to 5 millimeters in diameter. These particles come from the fragmentation and degradation of larger plastic items, such as bottles, bags, and fishing nets, as well as from the release of microplastic particles in personal care products like exfoliating scrubs and toothpaste.Here are some key points about marine microplastics:1. Sources: Marine microplastics originate from various sources, including: 1) Primary Microplastics: These are intentionally manufactured small plastic particles, such as microbeads in personal care products or pellets used in industrial processes.2) Secondary Microplastics: These result from the breakdown of larger plastic items due to environmental factors like sunlight, waves, and microbial activity.2. Environmental Impact: Marine microplastics pose significant environmental threats:3. Human Health: There are concerns about the potential impacts of microplastics on human health, as microplastics have been found in seafood and even drinking water. While the health effects are still being studied, ingestion of microplastics is a growing concern.4. Monitoring and Mitigation: Efforts to address marine microplastics include monitoring and research to better understand their distribution and impacts, regulations to limit the use of microplastics in products, and initiatives to clean up marine litter.5. International Agreements: Several international agreements and organizations, such as the United Nations' Clean Seas campaign and the Basel Convention, aim to address marine plastic pollution, including microplastics.6. Reduction Efforts: Reducing the production and use of single-use plastics, promoting recycling, and improving waste management practices are important steps in preventing the generation of marine microplastics.7. Public Awareness: Raising public awareness about the issue of marine microplastics and the importance of responsible plastic use and disposal is crucial in addressing this problem.Overall, marine microplastics are a significant environmental challenge, and efforts are ongoing at the global, national, and local levels to better understand, mitigate, and prevent their impact on marine ecosystems and human health.

1	Bacillus Phage Database is an interactive site that collects and shares information related to the discovery, characterization, and genomics of bacteriophages that infect Bacillus.

1	The Host-Microbiota Interactions Lab explores the relationship between humans and their microbiome- the community of microorganisms that live on and in us. The team focusses on gut bacteria and viruses and their influence in long-term growth, development and disease resistance of children from Westernized and Low- and Middle-Income countries. This database contains 142,809 non-redundant gut phage genomes from 28,060 metagenomes

1	PHASTER (PHAge Search Tool Enhanced Release) is a significant upgrade to the popular PHAST web server for the rapid identification and annotation of prophage sequences within bacterial genomes and plasmids. While the steps in the phage identification pipeline in PHASTER remain largely the same as in the original PHAST, numerous software improvements and significant hardware enhancements have now made PHASTER faster, more efficient, more visually appealing and much more user friendly. In particular, PHASTER is now 4.3X faster than PHAST when analyzing a typical bacterial genome. More specifically, software optimizations have made the backend of PHASTER 2.7X faster than PHAST. Likewise, the addition of more than 120 CPUs to the PHASTER compute cluster have greatly reduced processing times. PHASTER can now process a typical bacterial genome in 3 minutes from the raw sequence alone, or in 1.5 minutes when given a pre-annotated GenBank file. A number of other optimizations have been implemented, including automated algorithms to reduce the size and redundancy of PHASTER’s databases, improvements in handling multiple (metagenomic) queries and high user traffic, and the ability to perform automated look-ups against >14,000 previously PHAST/PHASTER annotated bacterial genomes (which can lead to complete phage annotations in seconds as opposed to minutes). PHASTER’s web interface has also been entirely rewritten. A new graphical genome browser has been added, gene/genome visualization tools have been improved, and the graphical interface is now more modern, robust, and user-friendly.

1	SEA-PHAGES (Science Education Alliance-Phage Hunters Advancing Genomics and Evolutionary Science) is a two-semester, discovery-based undergraduate research course that begins with simple digging in the soil to find new viruses, but progresses through a variety of microbiology techniques and eventually to complex genome annotation and bioinformatic analyses.The program aims to increase undergraduate interest and retention in the biological sciences through immediate immersion in authentic, valuable, yet accessible research. By finding and naming their own bacteriophages, students develop a sense of project ownership and have a ready-made personal research project at a fraction of the cost of traditional apprentice-based research programs. Some of the positive effects of the SEA-PHAGES program have been reported here.SEA-PHAGES is jointly administered by Graham Hatfull's group at the University of Pittsburgh and the Howard Hughes Medical Institute's Science Education division.

1	Viral Host Range database is a resource for virus-host interactions studies. How do I search for the host of a virus? If answering this question is trivial for some human pathogenic viruses, it is more puzzling for viruses in general. The Viral Host Range database (VHRdb) gives access to the experimental data to answer this question. The aim of the VHRdb is to provide to the community the data generated by scientists documenting the host range of their favorite virus through an easy (copy/paste) contribution process including benefits. Indeed, VHRdb integrates analysis tools to compare experimental datasets in many ways. Searching for the host range of a virus, or the other way around has never been easier!

1	Virus-Host DB organizes data about the relationships between viruses and their hosts, represented in the form of pairs of NCBI taxonomy IDs for viruses and their hosts. Virus-Host DB covers viruses with complete genomes stored in 1) NCBI/RefSeq and 2) GenBank whose accession numbers are listed in EBI Genomes. The host information is collected from RefSeq, GenBank (in free text format), UniProt, ViralZone, and manually curated with additional information obtained by literature surveys.

1	This resource provides all publicly available viral genome sequences and related information.

1	This database contains 38,880 PHROGs (protein orthologous groups) containing 868,340 proteins from complete genomes of viruses infecting bacteria or archaea (2,318 from RefSeq and 2,669 from GenBank, april 2018), in addition to 12,498 curated prophages derived from cultivated microbial isolates (Roux et al., 2015).Only one standardized annotation was attributed to each PHROG (using RefSeq annotations, and comparison of each PHROG to Pfam, UNIPROT, KEGG and the ACLAME database)This website provides access to :all prokaryotic virus genomes from the viruses table and select one to see its taxonomy, list of proteins, genomic map, etc...all PHROGs from the PHROGs table and select one to see its annotation, list of proteins, multiple alignment, comparison results to Pfam, Uniprot, KEGG, etc...

1	VIRFAM is dedicated to the recognition of head-neck-tail modules and of recombinase genes in phage genomes. You can use this server to search for remote homologs of specific protein families within protein sequences of bacteriophages. The process of one sequence, including profile generation and database scanning may last up to 5 minutes each. Please provide your email below to be kept informed.

1	The International Committee on Taxonomy of Viruses  (ICTV) is charged with the task of developing, refining, and maintaining a universal virus taxonomy. This task encompasses the classification of virus species and higher-level taxa according to the genetic and biological properties of their members; naming virus taxa; maintaining a database detailing the currently approved taxonomy; and providing the database, supporting proposals, and other virus-related information from an open-access, public web site. The ICTV web site (http://ictv.global) provides access to the current taxonomy database in online and downloadable formats, and maintains a complete history of virus taxa back to the first release in 1971. The ICTV has also published the ICTV Report on Virus Taxonomy starting in 1971. This Report provides a comprehensive description of all virus taxa covering virus structure, genome structure, biology and phylogenetics. The ninth ICTV report, published in 2012, is available as an open-access online publication from the ICTV web site. The current, 10th report (http://ictv.global/report/), is being published online, and is replacing the previous hard-copy edition with a completely open access, continuously updated publication. No other database or resource exists that provides such a comprehensive, fully annotated compendium of information on virus taxa and taxonomy.

1	The Cambridge Structural Database (CSD) is a comprehensive database of crystal structures of organic and metal-organic compounds. It is maintained and curated by the Cambridge Crystallographic Data Centre (CCDC), which is based in Cambridge, United Kingdom. The CSD is one of the most extensive and widely used resources for researchers in the field of chemistry and crystallography.Here are some key features and information about the Cambridge Structural Database (CSD):[1] Crystal Structures: The CSD contains detailed information about the three-dimensional atomic arrangements (crystal structures) of a vast number of chemical compounds. These compounds include organic molecules, inorganic compounds, and metal-organic complexes. Crystallographers from around the world contribute to the database.[2] Data Collection: The data in the CSD is collected from X-ray and neutron diffraction experiments. These experiments involve bombarding a crystal with X-rays or neutrons and analyzing how they scatter to determine the positions of atoms within the crystal lattice. This information is then used to create a detailed model of the crystal structure.[3] Search and Retrieval: Researchers can access the CSD to search for specific crystal structures or types of compounds using various search criteria. This allows them to find information about specific chemical structures or to explore patterns and trends in crystal structures.[4] Research and Applications: The CSD is invaluable for a wide range of scientific disciplines, including chemistry, materials science, and pharmacology. Researchers use it to study molecular conformations, intermolecular interactions, and crystal packing. It also aids in drug discovery, materials design, and the development of new chemical compounds.[5] Software and Tools: The CCDC provides software and tools that allow users to visualize, analyze, and manipulate crystal structure data from the CSD. Popular software packages like Mercury and ConQuest are used for these purposes.[6] Access: Access to the CSD is typically subscription-based, and it is widely used by academic institutions, research organizations, and pharmaceutical companies. Users can access the database through various software interfaces and web tools.[7] Quality Control: The CCDC performs rigorous quality control and validation checks on the crystal structure data contributed to the CSD to ensure accuracy and reliability.[8] Updates: The CSD is continually updated with new crystal structures as they become available through research publications and collaborations with crystallographers worldwide.

1	NAKB provides search, report, statistics, atlas and visualization pages for all nucleic-acid containing experimentally determined 3D structures held by NDB and by the Protein Data Bank (PDB), including all major methods: X-ray, NMR, and Electron Microscopy. For each structure, links are provided to external resources that annotate and analyze nucleic acid structures and their complexes.

1	Drugs.com is the largest, most widely visited, independent medicine information website available on the Internet. Our aim is to be the Internet’s most trusted resource for drug and related health information. We will achieve this aim by presenting independent, objective, comprehensive and up-to-date information in a clear and concise format for both consumers and healthcare professionals.

1	The Database of Experimental Biomaterials and their Biological Effect (DEBBIE) was an EU Horizon 2020 funded project to develop an open access database of biomaterials automatically curated from the scientific literature. DEBBIE was designed to facilitate a more efficient access to the large literature in the field, generate a comprehensive map of research activity and findings, and enable evidence-based selection of materials for medical applications.Beyond the development of database, the project was dedicated to the creation, adaptation and optimization of text mining tools for the biomaterials domain. These tools, including the DEBBIE retrieval and annotation pipeline (see illustration below), are openly available for download and use.

1	The dataset contains in total 1245 images of 22 virus classes captured with two different electron microscopes: an LEO (Zeiss, Oberkochen, Germany) with a Morada (Olympus) camera and a Tecnai 10 (FEI, Hillsboro, OR, USA) with a MegaView III (Olympus, Münster, Germany) camera

1	Since 1998, epocrates has served essential, continually researched and updated clinical content to more than a million users. Get to know the app our clinicians have called “my second brain” and “absolutely essential to modern practice.” Epocrates is a database used for not only DDI checking but also several healthcare services such as pill identification, medical calculator, and information resources for patients. The severity of DDI is stratified into four levels, including Contraindicated, Avoid/Use Alternative, Monitor/Modify Therapy, and Caution Advised

1	Chemical Entities of Biological Interest (ChEBI) is a publicly available database that focuses on the chemical entities found in living organisms. It is a resource used in bioinformatics, chemistry, and related fields to provide information about the chemical structures, nomenclature, and biological activities of various molecules, particularly those of biological relevance.Key features of ChEBI include:[1] Chemical Structure Information: ChEBI contains detailed information about the chemical structures of various molecules, including organic and inorganic compounds, peptides, nucleic acids, and more. It provides graphical representations of these structures.[2] Chemical Nomenclature: The database includes systematic chemical names, synonyms, and other nomenclatural information for each entry. This helps users identify and search for specific compounds.[3] Classification: ChEBI categorizes chemical entities into different classes and ontologies, such as small molecules, lipids, carbohydrates, and proteins. This classification aids in the organization and retrieval of data.[4] Biological Activities: ChEBI provides information about the biological activities and roles of chemical entities. This can include details about their interactions with proteins, enzymes, and other biomolecules.[5] Database Links: ChEBI is interconnected with other databases, allowing users to access additional information and cross-references related to a specific chemical entity. This feature facilitates data integration and retrieval.[6] Web-Based Interface: ChEBI offers a user-friendly web interface that allows researchers and scientists to search for specific chemical entities, view their structures, and access associated information easily.[7] Data Availability: ChEBI data is freely available to the public, making it a valuable resource for researchers, educators, and students in the fields of biology, chemistry, and bioinformatics.

1	The Proteomic Data Commons (PDC) offers access to highly curated and standardized biospecimen, clinical, and proteomic data. The PDC includes data from the Clinical Proteomic Tumor Analysis Consortium (CPTAC) program and will grow to include other sources over time. The data are open access and can be browsed interactively using a series of filters and accessed by an API.The Proteomic Data Commons (PDC) was developed to advance understanding of how proteins help to shape the risk, diagnosis, development, progression, and treatment of cancer. In-depth analysis of proteomic data allows the study of both how and why cancer develops and informs ways of tailoring treatment for individual patients using precision medicine.The data in the PDC are structured and queryable using the PDC data model and data dictionary. Submitted data are processed and then harmonized to maintain data and metadata consistency, integrity, and availability to the PDC users and the rest of the CRDC.All proteomic data in the PDC are open access and, with appropriate attribution, can be included in publications. Through the PDC, researchers will have access to highly curated and standardized biospecimen, clinical, and proteomic data, as well as an intuitive interface to filter, query, search, visualize, and download all data and metadata. In addition to the PDC’s graphical user interface, there is also an Application Programming Interface (API) that can be used to query the data programmatically.In addition to providing data, the PDC also offers analysis tools:Jbrowse – map peptides to the human genomePepquery – identify and validate novel peptidesMorpheus – quantitative data visualization and analysisThe data files of the PDC are available for analysis in the CRDC Cloud Resources. Specifically, PDC users can build cohorts of interest in the PDC portal and then analyze the associated data files in Seven Bridges Genomics.   

1	BFD was created by clustering 2.5 billion protein sequences from Uniprot/TrEMBL+Swissprot, Metaclust and Soil Reference Catalog Marine Eukaryotic Reference Catalog assembled by Plass.

1	The Integrated Canine Data Commons (ICDC) includes genomics, proteomics, and imaging data from naturally occurring cancer in canine cancer patients. Researchers can explore multiple types and collections of open-access data directly through the portal or through one of NCI's Cloud Resources. The Integrated Canine Data Commons (ICDC) was established to further research on human cancers by enabling comparative analysis with canine cancer. Canines have many genes similar to human genes, which are involved in cancers in similar ways. They develop spontaneous diseases and respond to treatments like humans, live in a family environment shared with humans, and like humans receive health care and participate in clinical trials. Canines are also of scientific interest because of their accelerated aging process.The data in the ICDC are structured and queryable according to the ICDC data model. Submitted data are harmonized to maintain data and metadata consistency, integrity and availability to the ICDC users and the rest of the CRDC.All data in the ICDC are open-access and, with appropriate attribution, can be included in publications. In addition to the ICDC’s graphical user interface, there is also an Application Programming Interface (API) that software programs may use to query the data.The data files of the ICDC are available for analysis in the CRDC Cloud Resources. ICDC users can build cohorts of interest in the ICDC and then analyze the associated data files in the Seven Bridges Cancer Genomics Cloud (SB-CGC).

1	The Imaging Data Commons (IDC) provides cloud-based access to a wide variety of medical imaging and metadata from The Cancer Imaging Archive and other NCI projects. Its connection to a wide variety of analytical tools allows researchers and data scientists to train and explore imaging models without downloading data.NCI Imaging Data Commons (IDC) is a cloud-based repository of publicly available cancer imaging data co-located with the analysis and exploration tools and resources. IDC is a node within the broader NCI Cancer Research Data Commons (CRDC)opens a new tab infrastructure that provides secure access to a large, comprehensive, and expanding collection of cancer research data. All data hosted by IDC will be available publicly. The current content of IDC is populated using the radiology collections from The Cancer Imaging Archive (TCIA) , as well as data collected by other major NCI initiatives, such as TCGA, CPTAC, NLST, and HTAN. IDC does not perform de-identification of images but will accept data de-identified by TCIA or other Data Coordinating Centers that are approved by NCI Security.IDC provides access to the data standardized using the Digital Imaging and Communication in Medicine (DICOM)  standard. IDC collaborates with the projects generating the data to harmonize alternative formats into DICOM representation. Its content includes not only images, but also image annotations and analysis results, and is linked using common identifiers to the other types of cancer data, such as proteomics and genomics datasets in the Cancer Research Data Commons (CRDC)opens a new tab. Access to the data is supported using standard interfaces. Given the IDC's role as an imaging data science platform, a major focus is on establishing best practices for imaging research. In this regard, a key role of IDC is in preparing and adapting commonly used tools for image analysis to be run on cloud environments with IDC-hosted datasets. Summarized derived data from analyses previously run will be associated with imaging data on IDC for ease of use by the research community.IDC contains various types of images and image-derived data harmonized using the DICOM standard. As of October 2022, IDC contains the following types of images:Clinical and preclinical imagingRadiological images (e.g., CT, MRI, PET)Digital pathology imagesMultispectral microscopy imagesImage annotations (e.g., planar and volumetric, regions of interest)Parametric maps derived from images (e.g., perfusion and diffusion maps)Measurements derived from the images (e.g., radiomics features for the annotated regions of interest)Expert assessments of the image findings (e.g., qualitative characterizations of lesion appearance)

1	The Pediatric Cancer Data Commons (PCDC) focuses on collecting, standardizing, and harmonizing disparate sources and types of pediatric cancer clinical research data, including clinical, genomic, and imaging data, from consortia, research groups, and institutions around the world.The Pediatric Cancer Data Commons (PCDC) houses the world’s largest set of harmonized clinical data for pediatric cancer research. With hundreds of international collaborators forming more than ten disease-specific consortia, we have collected and harmonized data from across more than forty countries and almost all types of pediatric cancer, and continue to grow. The PCDC Data Portal The PCDC Data Portal offers a unified platform where researchers can use our cohort explorer and other analysis tools to explore available data and assess study feasibility. Bringing multiple types of clinical data together in one place, the portal offers new opportunities for cross-disease research and interoperability with other data commons. Line-level data for research may be requested through our project application process. Anyone can create an account and explore the PCDC Data Portal. Video tutorials and other documentation are available here.PCDC Data DictionariesConsistent data standards are the foundation for usable, high-quality data. We work with pediatric cancer experts and the National Cancer Institute to develop consensus-based data dictionaries and map all clinical data in the PCDC to standardized terms. Our data dictionaries are available here.PCDC ConsortiaOur disease-specific alliances and consortia are now collecting and harmonizing data for more than a dozen types of pediatric cancer.ALL Data Commons – Acute Lymphoblastic LeukemiaC3P – Childhood Cancer PredispositionGlobal REACH – RetinoblastomaHIBiSCus – Bone TumorsINRG – NeuroblastomaINSPiRE – CNS TumorsINSTRuCT – Soft Tissue SarcomaINTERACT – Acute Myeloid LeukemiaMaGIC – Germ Cell TumorsNOBLE – Nasopharyngeal CarcinomaNODAL – Hodgkin LymphomaReproductive HOPE – Oncofertility

1	The Cancer Data Service (CDS) is a repository for cancer research data generated by NCI-funded programs that do not meet the submission criteria for a specific CRDC Data Repository.The repository accommodates: data that do not meet the minimum metadata standards for submission to another CRDC Repository.studies that are on a waiting list for submission to a specific CRDC Repository (e.g., GDC).studies that are in progress and need a place to store and analyze data during the acquisition phase.CDS currently hosts a variety of data types from NCI projects such as the Human Tumor Atlas Network (HTAN), Division of Cancer Control and Population Sciences (DCCPS), and Childhood Cancer Data Initiative (CCDI) as well as data from independent research projects.  The CDS is home to both open and controlled access data, however, the CDS Portal is accessible for users to search and browse with no login. This allows users to see if the CDS has data of interest before requesting access.  

1	The goal of the Dependency Map (DepMap) portal is to empower the research community to make discoveries related to cancer vulnerabilities by providing open access to key cancer dependencies analytical and visualization tools.To accelerate precision cancer medicine, we construct systematic key datasets, analytical and visualization tools, using broad panels of cancer models that represent the diversity of human cancers.Capture the genetic and molecular diversity of human cancer:To represent the diversity of human cancer, DepMap builds on the original Cancer Cell Line Encyclopedia (CCLE) project, which characterized 1000 cell line models. To date, more than 2000 models have been collected.Modeling human cancer will require the use of a variety of models. In the next phase of DepMap, we will incorporate non-traditional models to more comprehensively capture cancer-specific vulnerabilities across diverse cancer types.Identify genetic and molecular alterations in cancer cells:A variety of genomic and molecular alterations may occur in cancer cells as they grow and metastasize, leading to therapeutic vulnerabilities.To capture these alterations, we systematically profiled a panel of 1000 cell lines as part of the CCLE project.In the next phase of DepMap, we will be expanding these and creating key datasets to more comprehensively capture genome alterations. In addition, we will be building new omics pipelines, and creating new relevant features to support the discovery of new targets and biomarkers.Enumerate all genes that are required for cell growth and drug sensitivities:In DepMap, we use large-scale functional genomics profiling to identify the genes required for cell growth. To date, we have performed genome-wide RNAi and CRISPR loss-of-function screens in more than 1000 cancer cell lines.In parallel, we are employing a multiplexed approach (PRISM) to profile hundreds of cellular models for drug sensitivities. After profiling the drug repurposing library, we are continuing to profile new compounds of interest to create the largest oncology reference dataset to date.At the core of our activities, we are building new analytical tools to better capture these genetic dependencies and drug sensitivities. Methods such as DEMETER, DEMETER2, CERES and CHRONOS have helped us better model cancer dependencies and drug sensitivities.We are expanding to include new screening modalities, new perturbations and non-traditional models to more comprehensively capture gene dependencies and drug sensitivities.Create a map of cancer vulnerabilities:We are building connections across our datasets to identify relationships between genetic dependencies, drug sensitivities and cellular features. By linking gene dependencies and drug sensitivities to cancer genetic and molecular features, we can uncover new cancer vulnerabilities, identify biomarkers of response and gain insights into mechanisms of action.We are continuing to develop more tools to improve and interpret predictive models, new ways to integrate the data and create better apps to support target and biomarker discovery.

1	Motivations for the Cancer Cell Line Encyclopedia (CCLE)Cancer cell lines are the most commonly used models for studying cancer biology, validating cancer targets and for defining drug efficacy.  Prior to the CCLE, cell line investigations were limited to a few commonly used cell lines or at most the 60 cell lines of the NCI60 panel.  For example, at the time of the discovery of EGFR mutations in lung cancer, EGFR inhibitors had been developed using a single cell line, A549 as the EGFR-inhibitor sensitive model.  This starkly contrasts with the number of patients (n=952) treated on the initial phase III trials of EGFR inhibitors.  Hence, the profound sensitivity of cancers bearing activating EGFR mutations was initially missed, at least in part due to the lack of large-scale, robust well-defined cancer cell line models.  As The Cancer Genome Anatomy (TCGA) project embarked on the efforts to define the genetic basis of human cancers it was clear that a similar effort would be required to characterize the cancer cell lines. Initial forays into the large-scale genetic and chemical characterization cancer cell linesWith the advent of high-density SNP arrays, the Sellers lab undertook the genetic characterization of NCI60 cell lines using high density SNP arrays.  Intersecting the SNP-array derived copy-number and LOH data with mRNA expression date generated by the NCI60 cell line team led to the discovery of novel amplification events in melanoma targeting the MITF transcription factor.Following this work NCI60 cell line genomic DNA was subjected to mutation specific genotyping to identify known oncogenic mutations in K-RAS and other oncogenes. This data along with the published BRAF mutation data was used to search for selective compound sensitivities among  the 42,796 compounds for which the −log10(GI50)) was available from the NCI60 profiling efforts.  Here, several MEK inhibitors were found to have markedly increased anti-proliferative activity in BRAF mutant melanoma cells. In short, BRAF mutation predicted sensitivity to MEK inhibition a finding later confirmed in phase III trials. In aggregate, these data suggested that larger-scale genetic characterization of the cancer cell lines coupled to compound or other cell perturbations might unveil predictive drug sensitivities in cancer.Integrative genomic analyses identify MITF as a lineage survival oncogene amplified in malignant melanomaNature 2005;436(7047):117‐122. DOI:10.1038/nature03664BRAF mutation predicts sensitivity to MEK inhibitionNature 2006;439(7074):358‐362. DOI:10.1038/nature04304The Cancer Cell Line Encyclopedia Project - A collaboration between the Broad Institute and the Novartis Institutes for Biomedical ResearchIn 2006 Sellers (Novartis),  Garraway (Broad Institute) and Schlegel (Novartis) crafted the initial project plan for large-scale genetic characterization of ~1000 cancer cell lines. This project was subsequently renewed on two occasions and hence we think of these as the three phases of the CCLE project.Phase I of the Cancer Cell Line Encyclopedia projectInitiated in January 2008, the overarching goals of this collaboration were: 1) to conduct a detailed genetic and pharmacologic characterization of a large panel of human cancer models; 2) to develop integrated computational analyses that link distinct pharmacologic vulnerabilities to characteristic genetic, gene expression, and cell lineage patterns; and, 3) to translate cell line integrative genomics into cancer patient stratification. Accordingly, the team set out to generate the following datasets from comprehensive genetic characterization of 1000 human cancer models.  In phase I, the collective teams acquired 1000 cell lines directly from the relevant publicly accessible cell line repositories including ATCC (American Type Culture Collection), DSMZ (Deutsche Sammlung von Mikroorganismen und Zellkulturen) and  the KCLB (Korean Cell Line Bank). Thus, the genomics data generated are as close to the repository cell line derivatives as we could achieve. After expansion of each cell line, DNA and RNA was extracted and used to generate Affymetrix SNP 6.0 data, Affymetrix U133 2.0+ expression array data, point mutation profiles using a SNP genotyping platform called OncoMap 3.0. and hybrid capture exon sequencing of >1600 known or putative cancer genes across the CCLE.  Finally, pharmacologic testing was performed across ~500 cell lines for a set of anti-cancer therapeutics. It is important to note that XX cell lines were found to be mislabeled version of already known cell lines and XX cell lines were found to harbor no genetic alterations and had expression profiles consistent with fibroblasts.These data were reported in:The Cancer Cell Line Encyclopedia enables predictive modelling of anticancer drug sensitivityNature 2012, Mar 28;483(7391):603-7. DOI: 10.1038/nature11003Pharmacogenomic Agreement Between Two Cancer Cell Line Data SetsNature 2015, Dec 3;528(7580):84-7. DOI:10.1038/nature15736The data files from phase I of the CCLE can be found here Phase II of the Cancer Cell Line Encyclopedia projectPhase II of the CCLE project expanded on the original characterizations by applying the emerging Next-Gen sequencing to further expand and refine the characterization of expressed mRNAs through RNA-seq, by further characterizing genetic alterations through exome sequencing (in this case complimenting the work of the Sanger Center by filling in the uncovered cell lines), by characterizing the miRNA content of all cell lines, by quantifying the metabolite abundance of 225 metabolites across the CCLE, by mass reaction monitoring (MRM) mass spec quantification of bulk Histone H3 tail modifications, and by performing reverse phase protein array analysis on the CCLE in collaboration with Michael Davis and Gordon Mills at MD Anderson. Phase III of the Cancer Cell Line Encyclopedia projectAs characterization of cell lines at the level of nucleic acids reached new levels of completeness we continued to strive towards an understanding of the protein content of cell lines. The vast majority of therapeutics act by interrupting or altering protein function and with the growing interested in antibody-drug conjugates, antibody mediated cellular cytotoxicity (ADCC), and CAR-T cells all directed at surface proteins we sought to try and define the CCLE proteome through mass spectrometry. To this end, the Gygi lab performed Tandem-mass tagging mass spectrometry to quantify the abundance of proteins in whole cell extracts derived from 375 of the CCLE cell lines.  In addition, serine/threonine phosphorylation events were quantified by cxxxxx.  In collaboration with the Carr Mass Spectrometry platform at the Broad Institute tyrosine phosphorylation was quantified in a small set of cell lines under conditions of distinct therapeutic perturbations. 

1	The Drug Repurposing Hub is a curated and annotated collection of FDA-approved drugs, clinical trial drugs, and pre-clinical tool compounds with a companion information resource. Order library plates to screen yourself or collaborate with the Broad Institute’s Center for the Development of Therapeutics to see if an existing drug may work against your novel target, model system, or indication. While the collection will undoubtedly reveal new uses for developed drugs, its true power is unlocked when applied to discover new biological insights and disease mechanisms.Drug Repurposing Hub is an open-access repository of more than 6,000 compounds, many of which have been FDA approved. Researchers at the Hub have spent years curating and verifying these compounds, and are now testing them against disease models in hopes to find new uses for these highly optimized small molecules. They, along with researchers around the world who would not ordinarily have access to such a library, are also using this resource to glean new insights into the characteristics of disease--efforts that can also jumpstart new drug discovery programs.History tells us that repurposing works. Aspirin, for example, was originally developed as a painkiller, but was eventually discovered to be effective in preventing heart disease. In general, though, these kinds of discoveries are accidental.Researchers at the Broad Institute have created a systematic approach for this kind of “accidental” discovery, collecting these compounds and one-by-one documenting their chemical structure, effectiveness and prior uses in clinical trials. They are then bringing this knowledge together in a comprehensive open-sourced information hub.This library of compounds is continuously updated in order to build one of the most comprehensive and up-to-date biologically annotated collections, with scientists experimentally confirming the identity and purity of each drug.The Broad’s Drug Repurposing Hub is open-access. Any researcher can log-in, look up, and download the information contained in the Hub. They can search based on the characteristics of a specific compound or drug target.

1	The Genetic Perturbation Platform, formerly known as the RNA interference (RNAi) Platform, supports functional investigations of the mammalian genome that can reveal how genetic alterations lead to changes in phenotype.GPP develops technologies for perturbing genes and assists collaborators in experimental planning and execution by helping choose the best model system and experimental readout to assess the effects of genetic perturbation. Technologies applied at scale include CRISPR knockout, activation, interference, and base editing; RNAi; and open reading frame overexpression.

1	The Cancer Research Institute (CRI) iAtlas is an interactive web platform and a set of analytic tools for studying interactions between tumors and the immune microenvironment (Eddy et al., F1000Research 2020). These tools allow researchers to explore associations between a variety of genomic characterizations of immune response, clinical phenotypes, germline genetics, and response to immunotherapy. Immune checkpoint inhibitor analysis modules allow for interactive exploration of the relationship between possible biomarkers of immune response and the outcome of response to checkpoint blockade, by direct comparison and using multivariable statistical models. Underlying these modules is a harmonization of primary sequencing data from 12 immuno-oncology trials with genomics data and matched clinical data available in the public domain. iAtlas also allows researchers to identify how tumor-intrinsic alterations, including mutations, copy-number alterations, and neoantigens relate to the immune microenvironment as evidenced in cancer genomic studies.  The initial version of CRI iAtlas was based on an analysis performed by The Cancer Genome Atlas (TCGA) Research Network on the TCGA data set comprising over 10,000 tumor samples and 33 tumor types (Thorsson et al., Immunity 2018). In this analysis, each tumor sample was scored for a variety of readouts for immune response, including immune cell composition, adaptive cell receptor repertoire, cancer-immune subtypes, neoantigen load, and expression of genes coding for immunomodulatory proteins. iAtlas has now expanded to share immune characterization of data from another large  consortium:  Pan-Cancer Analysis of Whole Genomes (PCAWG).  Work is underway to incorporate additional immuno-oncology data sets and immune-related aspects of The Human Tumor Atlas Network (HTAN). CRI iAtlas is made possible through a collaboration between the Cancer Research Institute, Sage Bionetworks, the Institute for Systems Biology, and the Vincent Lab at the UNC Lineberger Comprehensive Cancer Center.

1	Launched in September of 2018, the Human Tumor Atlas Network (HTAN) is a National Cancer Institute (NCI)-funded Cancer MoonshotSM initiative through which a collaborative network of Research Centers and a central Data Coordinating Center are constructing 3-dimensional atlases of the cellular, morphological, and molecular features of human cancers as they evolve from precancerous lesions to advanced disease. Across a diverse set of cancer types, these atlases aim to define critical processes and events throughout the life cycle of human cancers, such as the transition of pre-malignant lesions to malignant tumors, the progression of malignant tumors to metastatic cancer, tumor response to therapeutics, and the development of therapeutic resistance. The diverse set of cancer types under investigation include tumors that affect minority and underserved populations, tumors with a hereditary component, and highly aggressive pediatric cancers.Within HTAN, ten Research Centers are working to identify the molecular and cellular conditions that cause healthy cells to become cancerous and that driver critical transitions in advanced cancers. Two atlas pilot projects – one Pre-Cancer Atlas Pilot Project (PCAPP) and one Human Tumor Atlas Pilot Project (HTAPP) – were funded previously by NCI and also are contributing data and resources to the Network. A single HTAN Data Coordinating Center (DCC) supports each of the atlas teams and the broader Network by coordinating Network activities, providing centralized resources for data and resource storage, access, and sharing, and conducting outreach to the community.

1	Patient-derived cancer models have become an essential tool in both cancer research, drug development and preclinical studies. Each model type - PDX, organoid and cell line - offers unique advantages and is better suited for specific research areas. Researchers, clinicians, bioinformaticians and analytical tool developers face the challenge of navigating a complex landscape to find suitable models and associated data across multiple commercial and academic resources without the benefit of shared data standards or interoperable data. CancerModels.Org aims to solve this problem by providing harmonized and integrated model attributes to support consistent searching across the originating resources.

1	WorldClim is a widely used set of global climate data layers that provides high-resolution climate data for various purposes, including ecological modeling, climate change research, and biodiversity assessments. These data layers represent historical climate conditions and projections of future climate conditions on a global scale. WorldClim data is freely available to the public and is commonly used in scientific research and environmental management.Key features of WorldClim include:[1] Spatial Resolution: WorldClim provides climate data at a high spatial resolution, typically ranging from 30 arc-seconds (approximately 1 km) to 2.5 arc-minutes (approximately 4 km), depending on the dataset and version.[2] Climate Variables: The dataset includes a range of climate variables, such as temperature (mean, minimum, and maximum), precipitation, and bioclimatic variables derived from temperature and precipitation data. These variables are typically available on a monthly, quarterly, or annual basis.[3] Historical and Future Data: WorldClim offers both historical climate data, typically spanning a 30-year period, as well as future climate projections based on different greenhouse gas emission scenarios. These future projections are often used to study the potential impacts of climate change.[4] Data Formats: WorldClim data is provided in various formats, including raster files (e.g., GeoTIFF), which can be easily integrated into Geographic Information Systems (GIS) software for spatial analysis.[5] Version Updates: WorldClim periodically updates its datasets to incorporate the latest climate models and data sources, ensuring that researchers have access to up-to-date information.

1	Micromedex 2.0 includes more than thirty items of drug information, including three books of over-the-counter and prescription drug monographs (one focused on pediatric and neonatal patients); one herbal monograph source; books focusing on pregnancy and lactation, poisoning or toxicology, laboratory tests, evidence-based information on diseases, and new drugs and drugs in development; the Physician's Desk Reference; RED BOOK (drug pricing); patient care handouts; and interactive tools including twenty clinical calculators, oral or topical drug interactions, intravenous compatibility, and pill identification. Micromedex's editorial team creates some items, while others are licensed from outside publishers. Micromedex includes less duplication than Lexicomp does. Instead, Micromedex offers a summary item that provides brief information on a drug or topic and a comprehensive item that provides in-depth information: for example, ToxPoints provides guidance for managing an emerging poisoning event and POISONDEX provides long-term management and research evidence on the mechanism of poisoning.

1	Embryogenesis and seed formation involve a multitude of highly interconnected developmental processes which are precisely controlled by a complex network of genetic pathway regulators. In Arabidopsis, seed development and maturation are regulated by the LEC1/AFL-B3 network of transcription factors consisting of the central factor LEC1 and the AFL-B3 factors ABI3, FUS3 LEC2 which share the highly conserved B3 domain.RIMAS presents detailed network diagrams which reflect the interactions of these transcription factor hierarchies, gene promoter elements, hormonal pathways, epigenetic processes and chromatin remodelling and provide an easy access to the relevant references.RIMAS network nomenclature is based on the agreed-upon convention for the display and handling of biological regulatory networks designated as Systems Biology Graphical Notation ( SBGN, Le Novère et al., 2009, Nature Biotech., 27, 735).RIMAS stands for regulatory interaction maps of Arabidopsis seed development, is a web-based information portal and provides a comprehensive regularly updated overview of regulatory pathways and genetic interactions during Arabidopsis embryo and seed development. The service provides access to standardized network diagrams, linked literature databases and possibilities to export diagrams in common exchange formats such as GML for modifying network layouts according to individual purposes and further application using tools such as VANTED ( VANTED, Björn H. Junker, Christian Klukas and Falk Schreiber, 2006, BMC Bioinformatics, 7:109) or other image formats.

1	The VMH database captures information on human and gut microbial metabolism and links this information to hundreds of diseases and nutritional data. At the core of the VMH lie hundreds of manually curated genome-scale metabolic models, which have been assembled based on genomic, biochemical, and physiological data. In numbers, VMH curated 1 human reconstruction, 818 microbe reconstructions, 19313 reactions, 5607 metabolites, 3695 human genes, 255 diseases, 8790 foodstuffs. 

1	Metabolism Regulation Maps is an effort focused on identifying and describing connections between human signalling and metabolic networks important for the regulation of metabolic processes and a better understanding of their role in health and disease. In Systems Biology, graph database approaches aim to facilitate integration, exploration and visualisation of information, which can be represented by graphs, with nodes and edges representing entities and relationships/connections among them, respectively (Lysenko et al. 2016). Previously, we developed the Recon2Neo4j framework (Balaur et al. 2016 PMID: 27993779) that offers a graph database representation to the human metabolic information (Thiele et. al. 2013) and aims to facilitate exploration of the integrated data. We extended the Recon2Neo4j framework to integrate information on the set of signalling processes and corresponding human pathways, extracted from the Neo4j graph database version of the Reactome Knowledgebase (http://www.reactome.org, accessed 20/03/2017) [Fabregat et al. 2018, PMID: 29377902; Fabregat et al. 2016, PMID: 26656494].A signalling process was defined as a process where at least one reactant and at least one product are proteins or protein complexes (as shown in the brief SBGN representation): We used Cypher queries and we extracted information on the set of signalling processes using the Reactome Knowledgebase. Details on the Cypher query for the identification of the set of signalling processes using the Reactome Knowledgebase are available in the ReactomeCypherQueries file.In Recon2Neo4j, a metabolic reaction is shown as a detailed subgraph with a node (given by the metabolic reaction name itself), connected by a set of edges (e.g. Consumption, Production, Catalysis) to nodes representing the involved biological entities, including the metabolites (reactants and products) and enzymes/catalyzers (proteins and complexes). In addition, the relationship between biological complexes and compound proteins (represented also as nodes) was represented by the “Part_Of” edge.Every protein acting as an enzyme in metabolic reactions in the Recon2Neo4j framework was checked for its involvement in signalling processes. Once such an enzymatic protein - signalling process pair was found, the process information was added to the framework as a Process node only if the process name did not already exist in the graph, (in order to have unique nodes only). Process information including the Reactome name, identifier, url was stored as attributes of the Process node and the enzymatic protein - process involvement relationship was represented by the “In_Process” edge connecting the Protein and Process corresponding nodes. Similarly, the involvement of protein compounds of complexes in signalling processes was also represented by the “In_Process” edges, connecting the Protein Compound and Process nodes of the involved protein-component and biological complex. Moreover, the set of human pathways containing the signalling processes included in the framework was also integrated into the framework. Specifically, pathways were represented by the Pathway nodes, (with their Reactome name, identifier, and url as node attributes), and the relationships between the signalling processes and pathways were shown by the “In_Pathway” edges connecting the corresponding Process and Pathway nodes. The data model of the extended version of the Recon2Neo4j to include information on 1) protein - process, and 2) process - pathways involvement relationships is illustrated in the Data model figure below.

1	"ACSN (https://acsn.curie.fr) is a web-based multi-scale resource of biological maps depicting molecular processes in cancer cell and tumor microenvironment. The Atlas represents interconnected cancer-related signalling and metabolic network maps. Molecular mechanisms are depicted on the maps at the level of biochemical interactions, forming a large seamless network of above 8000 reactions covering close to 3000 proteins and 800 genes and based on more than 4500 scientific publications. The Atlas is a ""geographic-like"" interactive ""world map"" of molecular interactions leading the hallmarks of cancer as described by Hanahan and Weinberg. Molecular mechanisms within cancer cell and components of tumor microenvironment are represented in the form of comprehensive maps manually created using systems biology standards, making these maps amenable for computational analysis. The content of the maps reflects the most recent knowledge on mechanisms implicated in cancer development.The maps of ACSN 2.0 (https://acsn.curie.fr/Temp/maps.html) are interconnected, the regulatory loops between cancer cell and tumor microenvironment are systematically depicted. The cross-talk between signalling mechanisms and metabolic processes in the cancer cells is explicitly depicted thanks to new feature of the Atlas: ACSN 2.0 is now connected to RECON metabolic network, the largest graphical representation of human metabolism.ACSN 2.0 is composed of 13 maps, which are all interconnected. There are six maps covering signalling processes involved in cancer cell development and four maps describing tumor microenvironment. In addition, there are 3 cell type-specific maps describing specific signalling within different cells types found in the surrounding mullei of cancer cell. This feature of ACSN 2.0 reflects heterogeneity of tumor microenvironment.The maps of ACSN 2.0 have an hierarchical structure. They are decomposed into functional modules with understandable network layout. Navigation of the ACSN 2.0 is intuitive thanks to Google Maps-like features of NaviCell web platform. The exploration of the Atlas is simplified due to the semantic zooming feature, allowing to explore the seamless Atlas and individual maps from ACSN 2.0 collection at different levels of details description.Cross-referencing with other databases and links to all scientific paper that were used for composition of the Atlas, allow the user to study in depth the features of ACSN 2.0 components.The ACSN content is permanently expanded with new signalling network maps and updated by the latest discoveries in the field of cancer-related cell signalling. In addition, ACSN is not only a cancer-oriented database: ACSN maps depict fundamental cell signalling processes and can be used in cell signalling research.The integrated NaviCell web-based tool box in the ACSN 2.0 resource, allows to import and visualize heterogeneous omics data on top of the ACSN 2.0 maps and to perform functional analysis of the maps. In addition, the associated NaviCom tool automatically generates ACSN-based molecular portraits of cancer using multi-level omics data from cancer data resources as cBioPortal."

1	The AsthmaMap project is led by the European Institute for Systems Biology and Medicine, Lyon, France. The effort was initiated as a part of the IMI U-BIOPRED (Unbiased Biomarkers for the Prediction of Respiratory Disease Outcomes) data analysis and integration platform and then continued within IMI eTRIKS project (European Translational Information and Knowledge Management Services).The AsthmaMap includes three interconnected layers of granularity: Cellular Interactions (CI), a high-level overview; Molecular Relations (MR), the intermediate level of details; Biochemical Mechanisms (BM), the most detailed layer. An important part of the AsthmaMap development is the involvement of top experts in the field of asthma, allergic diseases and lung diseases. This way we make sure we are building a trusted reference resource and the results of this work go towards practical applications in clinics.AsthmaMap is being developed in close collaboration with the LCSB Parkinson’s disease map team. MINERVA platform is employed for online visualisation.The AsthmaMap project progresses in alliance with other efforts of the Disease Maps Community and communicates with other groups for exchanging experience and best practices.

1	The Species 2000 & ITIS Catalogue of Life is planned to become a comprehensive catalogue of all known species of organisms on Earth. Rapid progress has been made recently and this, the twelfth edition of the Annual Checklist, contains 1,404,038 species. Please note that this is probably just slightly over 2/3 of the world's known species. This means that for many groups it continues to be deficient, and users will notice that many species are still missing from the Catalogue. The present Catalogue is compiled with sectors provided by 115 taxonomic databases from around the world. Many of these contain taxonomic data and opinions from extensive networks of specialists, so that the complete work contains contributions from more than 3,000 specialists from throughout the taxonomic profession. Species 2000 and ITIS teams peer review databases, select appropriate sectors and integrate the sectors into a single coherent catalogue with a single hierarchical classification. It is planned to introduce alternative taxonomic treatments and alternative classifications, but an important feature is that for those users who wish to use it, a single preferred catalogue, based on peer reviews, will continue to be provided.

1	The SIMBAD Astronomical Database is a comprehensive astronomical database maintained by the Centre de Données astronomiques de Strasbourg (CDS), which is a part of the French Paris-Meudon Observatory and also associated with the University of Strasbourg. The SIMBAD astronomical database provides basic data, cross-identifications, bibliography and measurements for astronomical objects outside the solar system. SIMBAD can be queried by object name, coordinates and various criteria.

1	BioCatalogue is a UK project, started in May 2008, between the myGrid team at the University of Manchester and the EMBL-EBI to build and maintain a comprehensive, curated catalogue of Web Services for the Life Sciences community.The BioCatalogue provides a common interface for registering, browsing and annotating Web Services to the Life Science community. Services in the BioCatalogue can be described and searched in multiple ways based upon their technical types, bioinformatics categories, user tags, service providers or data inputs and outputs. They are also subject to constant monitoring, allowing the identification of service problems and changes and the filtering-out of unavailable or unreliable resources. The system is accessible via a human-readable ‘Web 2.0’-style interface and a programmatic Web Service interface. The BioCatalogue follows a community approach in which all services can be registered, browsed and incrementally documented with annotations by any member of the scientific community.The BioCatalogue aggregates Life Science-specific content from other sources, classifying it according to an ontology. Entries can be annotated by the community, and verified manually by a curator. Provides monitoring of up-time and validation of service interfaces.

1	The cnfishbase database features a simple and user-friendly interface, facilitating easy access and analysis of fish data for users. The interface dynamically adapts to the different screen sizes of desktop computers, laptops, tablets, and mobile devices. At present, interactive distribution maps of more than 33 000 fish species are available, in both Chinese and English, enabling users can view the global distribution patterns and trends of a vast number of fish. Users can engage dynamic effects via cursor movement, access detailed information by title selection, and locally save images using the right-click function. (4) Novelty: The database uses the latest international fish classification system, better reflecting the phylogenetic relationships among fish compared to traditional morphological classification. Additionally, the database encompasses nearly all extant fish species, maintaining current and comprehensive representation. Notably, to accommodate the annual discovery of new species, the database undergoes yearly updates to ensure data accuracy.

1	Virus-Host DB organizes data about the relationships between viruses and their hosts, represented in the form of pairs of NCBI taxonomy IDs for viruses and their hosts. Virus-Host DB covers viruses with complete genomes stored in 1) NCBI/RefSeq and 2) GenBank whose accession numbers are listed in EBI Genomes. The host information is collected from RefSeq, GenBank (in free text format), UniProt, ViralZone, and manually curated with additional information obtained by literature surveys.Virus-Host DB is provided as a GenomeNet service supported by Supercomputer System of the Institute for Chemical Research, Kyoto University.

1	What is FRED? Short for Federal Reserve Economic Data, FRED is an online database consisting of hundreds of thousands of economic data time series from scores of national, international, public, and private sources. FRED, created and maintained by the Research Department at the Federal Reserve Bank of St. Louis, goes far beyond simply providing data: It combines data with a powerful mix of tools that help the user understand, interact with, display, and disseminate the data. In essence, FRED helps users tell their data stories. The purpose of this article is to guide the potential (or current) FRED user through the various aspects and tools of the database.

1	The Minor Planet Center (MPC) is the single worldwide location for receipt and distribution of positional measurements of minor planets, comets and outer irregular natural satellites of the major planets. The MPC is responsible for the identification, designation and orbit computation for all of these objects. This involves maintaining the master files of observations and orbits, keeping track of the discoverer of each object, and announcing discoveries to the rest of the world via electronic circulars and an extensive website. The MPC operates at the Smithsonian Astrophysical Observatory, under the auspices of Division F of the International Astronomical Union (IAU).

1	SIMBAD (Set of Identifications, Measurements, and Bibliography for Astronomical Data) is a significant astronomical database maintained and provided by the Centre de Données astronomiques de Strasbourg (CDS) in France. SIMBAD's primary objective is to store and provide detailed information about various celestial objects, including stars, galaxies, quasars, planets, star clusters, and more

0 Frequently Asked Questions

0 People

0 News

0 Our partners

0 youtube

0 Contact

0 Suggestions

0 Jobs
